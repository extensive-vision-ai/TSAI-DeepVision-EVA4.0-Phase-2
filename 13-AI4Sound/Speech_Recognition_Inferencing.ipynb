{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech_Recognition_Inferencing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMOt1CjmnnJDpjBhaAU/k9u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyajitghana/TSAI-DeepVision-EVA4.0-Phase-2/blob/master/13-AI4Sound/Speech_Recognition_Inferencing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHk9RHZtor2l",
        "outputId": "4e586274-0ea6-4116-ac84-aac5051b7a73"
      },
      "source": [
        "! pip install torchaudio==0.7.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchaudio==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/23/6b54106b3de029d3f10cf8debc302491c17630357449c900d6209665b302/torchaudio-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.6/dist-packages (from torchaudio==0.7.0) (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchaudio==0.7.0) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchaudio==0.7.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchaudio==0.7.0) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchaudio==0.7.0) (3.7.4.3)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d6ajUfp8429",
        "outputId": "1db4c74c-c6b9-4442-b9b7-b99b9b8c9ecb"
      },
      "source": [
        "! pip install SoundFile"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting SoundFile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from SoundFile) (1.14.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->SoundFile) (2.20)\n",
            "Installing collected packages: SoundFile\n",
            "Successfully installed SoundFile-0.10.3.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "1QepWtkspzsr",
        "outputId": "7dc0f028-a3c8-497a-cc72-1e0ac4880ebd"
      },
      "source": [
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=12MmbJioSAA-hs5y-RpHF0-Al5nAHdcgG'\n",
        "output = 'speech-recognition-residual-model.scripted.pt'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12MmbJioSAA-hs5y-RpHF0-Al5nAHdcgG\n",
            "To: /content/speech-recognition-residual-model.scripted.pt\n",
            "94.9MB [00:00, 129MB/s] \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'speech-recognition-residual-model.scripted.pt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-0jiSmOqU7S",
        "outputId": "6df8ae05-7a15-4a5c-fc38-cf4bfc3ed2de"
      },
      "source": [
        "! wget -O speech_commands_v0.01.tar.gz http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz\n",
        "! tar xzf speech_commands_v0.01.tar.gz \n",
        "! ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-25 19:10:24--  http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 173.194.217.128, 2607:f8b0:400c:c0d::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|173.194.217.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1489096277 (1.4G) [application/gzip]\n",
            "Saving to: ‘speech_commands_v0.01.tar.gz’\n",
            "\n",
            "speech_commands_v0. 100%[===================>]   1.39G   242MB/s    in 7.1s    \n",
            "\n",
            "2020-11-25 19:10:32 (200 MB/s) - ‘speech_commands_v0.01.tar.gz’ saved [1489096277/1489096277]\n",
            "\n",
            "_background_noise_  LICENSE\t speech_commands_v0.01.tar.gz\n",
            "bed\t\t    marvin\t speech-recognition-residual-model.scripted.pt\n",
            "bird\t\t    nine\t stop\n",
            "cat\t\t    no\t\t testing_list.txt\n",
            "dog\t\t    off\t\t three\n",
            "down\t\t    on\t\t tree\n",
            "eight\t\t    one\t\t two\n",
            "five\t\t    README.md\t up\n",
            "four\t\t    right\t validation_list.txt\n",
            "go\t\t    sample_data  wow\n",
            "happy\t\t    seven\t yes\n",
            "house\t\t    sheila\t zero\n",
            "left\t\t    six\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrFhy1yooh0S",
        "outputId": "aa26c4c9-c2bb-4e80-99bb-f3149f4e4579"
      },
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import soundfile as sf\n",
        "import io"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
            "  '\"sox\" backend is being deprecated. '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri-kGjzOrQLB"
      },
      "source": [
        "class TextTransform:\n",
        "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
        "    def __init__(self):\n",
        "        char_map_str = \"\"\"\n",
        "        ' 0\n",
        "        <SPACE> 1\n",
        "        a 2\n",
        "        b 3\n",
        "        c 4\n",
        "        d 5\n",
        "        e 6\n",
        "        f 7\n",
        "        g 8\n",
        "        h 9\n",
        "        i 10\n",
        "        j 11\n",
        "        k 12\n",
        "        l 13\n",
        "        m 14\n",
        "        n 15\n",
        "        o 16\n",
        "        p 17\n",
        "        q 18\n",
        "        r 19\n",
        "        s 20\n",
        "        t 21\n",
        "        u 22\n",
        "        v 23\n",
        "        w 24\n",
        "        x 25\n",
        "        y 26\n",
        "        z 27\n",
        "        \"\"\"\n",
        "        self.char_map = {}\n",
        "        self.index_map = {}\n",
        "        for line in char_map_str.strip().split('\\n'):\n",
        "            ch, index = line.split()\n",
        "            self.char_map[ch] = int(index)\n",
        "            self.index_map[int(index)] = ch\n",
        "        self.index_map[1] = ' '\n",
        "\n",
        "    def text_to_int(self, text):\n",
        "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
        "        int_sequence = []\n",
        "        for c in text:\n",
        "            if c == ' ':\n",
        "                ch = self.char_map['<SPACE>']\n",
        "            else:\n",
        "                ch = self.char_map[c]\n",
        "            int_sequence.append(ch)\n",
        "        return int_sequence\n",
        "\n",
        "    def int_to_text(self, labels):\n",
        "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
        "        string = []\n",
        "        for i in labels:\n",
        "            string.append(self.index_map[i])\n",
        "        return ''.join(string).replace('<SPACE>', ' ')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xAU6jQdrlAS"
      },
      "source": [
        "text_transform = TextTransform()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDRm0bUjqvjN"
      },
      "source": [
        "model = torch.jit.load(\"/content/speech-recognition-residual-model.scripted.pt\", map_location=\"cpu\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ftQTj97ovIn",
        "outputId": "964950df-8734-4e15-9424-f4b49bfe7962"
      },
      "source": [
        "audio_transform = torchaudio.transforms.MelSpectrogram() "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchaudio/functional.py:318: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  \"At least one mel filterbank has all zero values. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RCYQwnj3p9Ei",
        "outputId": "67268d1c-804b-4b28-bd4e-45e60c453b69"
      },
      "source": [
        "# waveform, sample_rate = torchaudio.load(\"cat/004ae714_nohash_0.wav\", normalization=True)\n",
        "waveform, _ = torchaudio.load(\"/content/stop/004ae714_nohash_0.wav\", normalization=True) # its normalized by default anyways\n",
        "input_audio = audio_transform(waveform)\n",
        "with torch.no_grad():\n",
        "    out = model(input_audio.unsqueeze(0))\n",
        "arg_maxes = torch.argmax(out, dim=2)\n",
        "decodes = []\n",
        "targets = []\n",
        "blank_label = 28\n",
        "collapse_repeated = True\n",
        "for i, args in enumerate(arg_maxes):\n",
        "    decode = []\n",
        "    for j, index in enumerate(args):\n",
        "        if index != blank_label:\n",
        "            if collapse_repeated and j != 0 and index == args[j -1]:\n",
        "                continue\n",
        "            decode.append(index.item())\n",
        "    decodes.append(text_transform.int_to_text(decode))\n",
        "decodes[0]"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'stop '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za9Q8Zfh-w9L"
      },
      "source": [
        "in_file = open(\"/content/happy/07363607_nohash_0.wav\", \"rb\") # opening for [r]eading as [b]inary\n",
        "data = in_file.read()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVJgK1bn-w9L"
      },
      "source": [
        "data, sample_rate = sf.read(io.BytesIO(data))\n",
        "waveform, _ = torch.from_numpy(data).float(), sample_rate\n",
        "waveform = waveform.unsqueeze(0)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKjkWXBS7wxV",
        "outputId": "667a5e67-9a6b-4f28-f4b7-de4b7ff3b45f"
      },
      "source": [
        "type(waveform)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_ykDCKDqmr8"
      },
      "source": [
        "input_audio = audio_transform(waveform)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlpKPaGBquJ-",
        "outputId": "43a15c89-6af2-45fe-9c89-692a02615813"
      },
      "source": [
        "input_audio.shape"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 128, 81])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YH6hW_2q2JK"
      },
      "source": [
        "with torch.no_grad():\n",
        "    out = model(input_audio.unsqueeze(0))"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL7GQZz6rHO5"
      },
      "source": [
        "arg_maxes = torch.argmax(out, dim=2)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9686A26drPUf",
        "outputId": "661fd1f1-102b-4348-db41-23f06ef29317"
      },
      "source": [
        "arg_maxes"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,  5, 28, 16, 28, 28, 28,\n",
              "         28, 28, 28, 28, 28, 28, 28, 28,  8, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
              "         28, 28, 28, 28, 28]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEziJjFRrmYN"
      },
      "source": [
        "decodes = []\n",
        "targets = []\n",
        "blank_label = 28\n",
        "collapse_repeated = True\n",
        "for i, args in enumerate(arg_maxes):\n",
        "    decode = []\n",
        "    for j, index in enumerate(args):\n",
        "        if index != blank_label:\n",
        "            if collapse_repeated and j != 0 and index == args[j -1]:\n",
        "                continue\n",
        "            decode.append(index.item())\n",
        "    decodes.append(text_transform.int_to_text(decode))"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BDwzUHPAr3LI",
        "outputId": "7c8e5632-70ec-4c93-b0a4-7acda984421c"
      },
      "source": [
        "decodes[0]"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dog'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUEMp9fr_I5P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}